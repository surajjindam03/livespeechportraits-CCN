{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajjindam03/livespeechportraits-CCN/blob/main/CCN_project_implementation_(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First download the github code as zip file to local and then extarct it.\n",
        "Then copy the datasets from the drive link and and place it in the data folder.\n",
        "Now push the entire folder to google drive.\n",
        "**Mount the drive in Colab as shown below**"
      ],
      "metadata": {
        "id": "9PreHvL1S7eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fzi6UDIvVowv",
        "outputId": "956c49b6-9d19-4fdc-c75e-86ffcc60ec18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go the the directory where the demo.py files exists in the drive.\n",
        "\n",
        "**Note:** Modify the below command to match your directory"
      ],
      "metadata": {
        "id": "Ag3W2JeBS0bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/LiveSpeechPortraits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAodws4JVxzq",
        "outputId": "8c9454ce-a9f4-4b79-a167-74a09b83691a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/LiveSpeechPortraits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing the dominate package**"
      ],
      "metadata": {
        "id": "K-q9ILRjzAOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dominate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tysMGQ8goFXL",
        "outputId": "fc26d063-c2a8-4ddb-f42a-e0b7bb20b8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dominate\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing albumenations package**"
      ],
      "metadata": {
        "id": "pfbIbFEazXoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==0.5.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOMq7CQaoh9x",
        "outputId": "307a7461-8613-4143-9e31-4ab54d699f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.5.2\n",
            "  Downloading albumentations-0.5.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m963.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.5.2) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations==0.5.2) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.5.2) (0.19.3)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.5.2) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==0.5.2) (6.0.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.5.2) (4.9.0.80)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (2.31.6)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (2.0.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (3.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2024.4.24)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.5.2) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.5.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.5.2) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.5.2) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.5.2) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.5.2) (2.8.2)\n",
            "Installing collected packages: albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.3.1\n",
            "    Uninstalling albumentations-1.3.1:\n",
            "      Successfully uninstalled albumentations-1.3.1\n",
            "Successfully installed albumentations-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Running the demo.py **inference code** using the below command:\n",
        "\n",
        "**!python demo.py --id May --driving_audio ./data/Input/00083.wav --device cuda**\n",
        "\n",
        "**Below are the parameters used in running the commands:**\n",
        "\n",
        "**# Add argument for person ID**:\n",
        "\n",
        "('--id', **default value='May'**, this is nothing but the person name\"). These are nothing but the pre-trained models and data which is present in the data folder. There are totally Five subjects data are released (May, Obama1, Obama2, Nadella and McStay). You can use other values like for e.g. Obama1, Obama2, May, Nadella, McStay.\n",
        "\n",
        "**# Add argument for driving audio path)**:\n",
        "('--driving_audio', default='./data/input/00083.wav', help=\"path to driving audio\")  \n",
        "\n",
        "**# Add argument for saving intermediate results**:\n",
        "    ('--save_intermediates', default=0, help=\"whether to save intermediate results\")  \n",
        "\n",
        "**# Add argument for device (CPU or GPU)**:\n",
        "    parser.add_argument('--device', type=str, default='cpu', help='use cuda for GPU or use cpu for CPU')\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ylfhJCj3wBQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python demo.py --id May --driving_audio ./data/Input/00083.wav --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzQ9HSXkm-WV",
        "outputId": "9629d893-15a0-4ca3-c9f6-183651e191cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opt: Namespace(task='Audio2Feature', model='audio2feature', dataset_mode='audiovisual', name='Audio2Feature', gpu_ids='0', checkpoints_dir='./checkpoints/', dataset_names='default_name', dataroot='default_path', frame_jump_stride=4, num_threads=0, batch_size=32, serial_batches=False, max_dataset_size=inf, audio_encoder='APC', feature_decoder='LSTM', loss='L2', A2L_GMM_ndim=75, sequence_length=240, FPS=60, sample_rate=16000, audioRF_history=60, audioRF_future=0, feature_dtype='pts3d', ispts_norm=1, use_delta_pts=1, frame_future=18, predict_length=1, only_mouth=1, APC_hidden_size=512, APC_rnn_layers=3, APC_residual=False, APC_frame_history=0, LSTM_hidden_size=256, LSTM_output_size=80, LSTM_layers=3, LSTM_dropout=0, LSTM_residual=False, LSTM_sequence_length=60, verbose=False, suffix='', phase='test', load_epoch='500', eval=False, time_frame_length=1)\n",
            "----------------- Options ---------------\n",
            "             A2L_GMM_ndim: 75                            \n",
            "        APC_frame_history: 0                             \n",
            "          APC_hidden_size: 512                           \n",
            "             APC_residual: False                         \n",
            "           APC_rnn_layers: 3                             \n",
            "                      FPS: 60                            \n",
            "             LSTM_dropout: 0                             \n",
            "         LSTM_hidden_size: 256                           \n",
            "              LSTM_layers: 3                             \n",
            "         LSTM_output_size: 80                            \n",
            "            LSTM_residual: False                         \n",
            "     LSTM_sequence_length: 60                            \n",
            "           audioRF_future: 0                             \n",
            "          audioRF_history: 60                            \n",
            "            audio_encoder: APC                           \n",
            "               batch_size: 32                            \n",
            "          checkpoints_dir: ./checkpoints/                \n",
            "                 dataroot: default_path                  \n",
            "             dataset_mode: audiovisual                   \n",
            "            dataset_names: default_name                  \n",
            "                     eval: False                         \n",
            "          feature_decoder: LSTM                          \n",
            "            feature_dtype: pts3d                         \n",
            "             frame_future: 18                            \n",
            "        frame_jump_stride: 4                             \n",
            "                  gpu_ids: 0                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "               ispts_norm: 1                             \n",
            "               load_epoch: 500                           \n",
            "                     loss: L2                            \n",
            "         max_dataset_size: inf                           \n",
            "                    model: audio2feature                 \n",
            "                     name: Audio2Feature                 \n",
            "              num_threads: 0                             \n",
            "               only_mouth: 1                             \n",
            "                    phase: test                          \n",
            "           predict_length: 1                             \n",
            "              sample_rate: 16000                         \n",
            "          sequence_length: 240                           \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                     task: Audio2Feature                 \n",
            "        time_frame_length: 1                             \n",
            "            use_delta_pts: 1                             \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "----------------- Options ---------------\n",
            "          A2H_GMM_ncenter: 1                             \n",
            "             A2H_GMM_ndim: 12                            \n",
            "        A2H_GMM_sigma_min: 0.03                          \n",
            "         A2H_wavenet_cond: True                          \n",
            "A2H_wavenet_cond_channels: 512                           \n",
            "A2H_wavenet_dilation_channels: 128                           \n",
            "A2H_wavenet_input_channels: 12                            \n",
            "  A2H_wavenet_kernel_size: 2                             \n",
            "A2H_wavenet_residual_blocks: 2                             \n",
            "A2H_wavenet_residual_channels: 128                           \n",
            "A2H_wavenet_residual_layers: 7                             \n",
            "A2H_wavenet_skip_channels: 256                           \n",
            "     A2H_wavenet_use_bias: True                          \n",
            "        APC_frame_history: 60                            \n",
            "          APC_hidden_size: 512                           \n",
            "             APC_residual: False                         \n",
            "           APC_rnn_layers: 3                             \n",
            "                      FPS: 60                            \n",
            "           audioRF_future: 0                             \n",
            "          audioRF_history: 60                            \n",
            "            audio_encoder: APC                           \n",
            "            audio_windows: 2                             \n",
            "audiofeature_input_channels: 80                            \n",
            "               batch_size: 32                            \n",
            "          checkpoints_dir: ./checkpoints/                \n",
            "                 dataroot: path                          \n",
            "             dataset_mode: audiovisual                   \n",
            "            dataset_names: name                          \n",
            "                     eval: False                         \n",
            "          feature_decoder: WaveNet                       \n",
            "             frame_future: 15                            \n",
            "        frame_jump_stride: 1                             \n",
            "                  gpu_ids: 0                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "               load_epoch: 500                           \n",
            "                     loss: GMM                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: audio2headpose                \n",
            "                     name: Audio2Headpose                \n",
            "              num_threads: 0                             \n",
            "                    phase: test                          \n",
            "           predict_length: 5                             \n",
            "              sample_rate: 16000                         \n",
            "          sequence_length: 240                           \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                     task: Audio2Headpose                \n",
            "        time_frame_length: 1                             \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "------------ Options -------------\n",
            "batch_size: 1\n",
            "checkpoints_dir: ./checkpoints/\n",
            "dataroot: ./data/\n",
            "dataset_mode: face\n",
            "dataset_names: ['name']\n",
            "debug: False\n",
            "display_id: 0\n",
            "display_winsize: 512\n",
            "fineSize: 512\n",
            "fp16: 0\n",
            "gpu_ids: [0]\n",
            "input_nc: 1\n",
            "isH5: 1\n",
            "isMask: 0\n",
            "isTrain: False\n",
            "loadSize: 512\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: feature2face\n",
            "n_blocks_E: 3\n",
            "n_downsample_E: 3\n",
            "n_downsample_G: 8\n",
            "name: TestRender\n",
            "ngf: 64\n",
            "ngf_E: 16\n",
            "no_flip: 1\n",
            "num_threads: 0\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: scaleWidth\n",
            "serial_batches: False\n",
            "suffix: .jpg\n",
            "task: Feature2Face\n",
            "test_dataset_names: ['name']\n",
            "tf_log: True\n",
            "verbose: False\n",
            "-------------- End ----------------\n",
            "---------- Loading Model: APC-------------\n",
            "---------- Loading Model: Audio2Feature -------------\n",
            "initialize network with normal\n",
            "model [Audio2FeatureModel] was created\n",
            "loading the model from ./data/May/checkpoints/Audio2Feature.pkl\n",
            "---------- Networks initialized -------------\n",
            "[Network Audio2Feature] Total number of parameters : 3.064 M\n",
            "-----------------------------------------------\n",
            "---------- Loading Model: Audio2Headpose -------------\n",
            "initialize network with normal\n",
            "model [Audio2HeadposeModel] was created\n",
            "loading the model from ./data/May/checkpoints/Audio2Headpose.pkl\n",
            "---------- Networks initialized -------------\n",
            "[Network Audio2Headpose] Total number of parameters : 4.267 M\n",
            "-----------------------------------------------\n",
            "---------- Loading Model: Feature2Face -------------\n",
            "dataset [FaceDataset] was created\n",
            "---------- Generator networks initialized -------------\n",
            "-------------------------------------------------------\n",
            "initialize network with normal\n",
            "model [Feature2FaceModel] was created\n",
            "loading the model from ./data/May/checkpoints/Feature2Face.pkl\n",
            "---------- Networks initialized -------------\n",
            "[Network Feature2Face_G] Total number of parameters : 121.790 M\n",
            "-----------------------------------------------\n",
            "Processing audio: 00083 ...\n",
            "1. Computing APC features...\n",
            "2. Manifold projection...\n",
            "LLE projection: 100% 1374/1374 [00:00<00:00, 21977.80it/s]\n",
            "3. Audio2Mouth inference...\n",
            "4. Headpose inference...\n",
            "generating headpose: 100% 672/672 [00:07<00:00, 87.44it/s] \n",
            "5. Post-processing...\n",
            "100% 672/672 [00:00<00:00, 20484.26it/s]\n",
            "6. Image2Image translation & Saving results...\n",
            "Image2Image translation inference: 100% 672/672 [00:57<00:00, 11.71it/s]\n",
            "writing video: 100% 672/672 [00:07<00:00, 94.86it/s]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, avi, from './results/May/00083/tmp.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:11.20, start: 0.000000, bitrate: 1808 kb/s\n",
            "  Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], 1795 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #1.0 : mono\n",
            "\u001b[0mInput #1, wav, from './results/May/00083/tmp.wav':\n",
            "  Duration: 00:00:11.20, bitrate: 256 kb/s\n",
            "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "File './results/May/00083/00083.avi' already exists. Overwrite? [y/N] y\n",
            "Output #0, avi, to './results/May/00083/00083.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], q=2-31, 1795 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
            "  Stream #0:1: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "  Stream #1:0 -> #0:1 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "frame=  670 fps=0.0 q=-1.0 Lsize=    2825kB time=00:00:11.16 bitrate=2072.5kbits/s speed= 595x    \n",
            "video:2447kB audio:350kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.996688%\n",
            "writing video: 100% 672/672 [00:05<00:00, 127.79it/s]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, avi, from './results/May/00083/tmp.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:11.20, start: 0.000000, bitrate: 3168 kb/s\n",
            "  Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], 3157 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #1.0 : mono\n",
            "\u001b[0mInput #1, wav, from './results/May/00083/tmp.wav':\n",
            "  Duration: 00:00:11.20, bitrate: 256 kb/s\n",
            "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "File './results/May/00083/00083_feature_maps.avi' already exists. Overwrite? [y/N] y\n",
            "Output #0, avi, to './results/May/00083/00083_feature_maps.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], q=2-31, 3157 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
            "  Stream #0:1: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "  Stream #1:0 -> #0:1 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "frame=  670 fps=0.0 q=-1.0 Lsize=    4684kB time=00:00:11.16 bitrate=3436.1kbits/s speed= 446x    \n",
            "video:4306kB audio:350kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.599087%\n",
            "deleting intermediate images: 100% 1344/1344 [00:02<00:00, 567.88it/s]\n",
            "Finish!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**The result which is the final video/ talking head animation will be saved in the results folder**"
      ],
      "metadata": {
        "id": "HSoLxu3mxzIf"
      }
    }
  ]
}